#!/bin/bash
#SBATCH --job-name=rloo
#SBATCH --output=out/%A/rlooarr_%A_%a.out
#SBATCH --error=out/%A/rlooarr_%A_%a.err
#SBATCH --array=5
#SBATCH --time=36:00:00
#SBATCH --partition=general
#SBATCH --gres=gpu:1
#SBATCH --constraint=VRAM_48GB
#SBATCH --cpus-per-task=4

set -euo pipefail

# Source checkpoint list if it exists (generated by launch_pretrain_array.sh)
checkpoint_file=".checkpoint_list.sh"
if [ -f "$checkpoint_file" ]; then
    source "$checkpoint_file"
else
    # Default: no checkpoints
    checkpoint_list=()
fi

# Define bash arrays for the parameters
B_list=(64 64 64 64 32 32 32 32)
G_list=(16 16 16 16 32 32 32 32)
E_list=(1 2.5 5 10 1 2.5 5 10)
# H_list=("False" "False" "False" "False" "False" "False" "False" "False")

# Get values for this task
B=${B_list[$SLURM_ARRAY_TASK_ID]}
G=${G_list[$SLURM_ARRAY_TASK_ID]}
E=${E_list[$SLURM_ARRAY_TASK_ID]}

# Get checkpoint for this task (if available)
task_idx=$((SLURM_ARRAY_TASK_ID))
if [ ${#checkpoint_list[@]} -gt 0 ] && [ $task_idx -ge 0 ] && [ $task_idx -lt ${#checkpoint_list[@]} ]; then
    checkpoint_val="${checkpoint_list[$task_idx]}"
else
    checkpoint_val=""
fi

# Generate abbreviated run_name from parameters
# q_head_input_detached: True -> T, False -> F
# q_head_input_form: "intermediate output" -> io, "first puzzle emb" -> fpe  
# H_deterministic_mode: "separate weights" -> sw, "False" -> F

# if [ "$H" = "separate weights" ]; then
#     mode_abbrev="sw"
# elif [ "$H" = "False" ]; then
#     mode_abbrev="F"
# elif [ "$H" = "skip noise" ]; then
#     mode_abbrev="sn"
# else
#     mode_abbrev="unknown"
# fi

# if [ "$time_embed_val" = "True" ]; then
#     time_embed_abbrev="TE"
# elif [ "$time_embed_val" = "False" ]; then
#     time_embed_abbrev="NTE"
# else
#     time_embed_abbrev="unknown"
# fi

run_name="rloo_B$B/G$G/E$E"

if [ -n "$checkpoint_val" ]; then
    echo "Running task $SLURM_ARRAY_TASK_ID: run_name=$run_name, checkpoint=$checkpoint_val"
else
    echo "Running task $SLURM_ARRAY_TASK_ID: run_name=$run_name"
fi

eval "$(conda shell.bash hook)"
conda activate trp

python_cmd="python train_rloo.py \
  --config-name=cfg_rloo \
  global_batch_size=$B \
  num_rollouts_per_input=$G \
  rloo.entropy_coef=$E \
  run_name=\"$run_name\""

# Add checkpoint if specified
if [ -n "$checkpoint_val" ]; then
    python_cmd="$python_cmd +load_checkpoint=\"$checkpoint_val\""
fi

eval $python_cmd

echo "Completed task $SLURM_ARRAY_TASK_ID"